## Outliers

An outlier is a data point which is significantly different from the remaining data. 
"An outlier is an observation which deviates so much from the other observations as to arouse suspicions 
that it was generated by a different mechanism." [D. Hawkins. Identification of Outliers, Chapman and Hall , 1980.]


### Should outliers be removed?

Depending on the context, outliers either deserve special attention or should be completely ignored. 
Take the example of revenue forecasting: if unusual spikes of revenue are observed, it's probably a good idea 
to pay extra attention to them and figure out what caused the spike. In the same way, an unusual transaction on 
a credit card is usually a sign of fraudulent activity, which is what the credit card issuer wants to prevent. 
So in instances like these, it is useful to look for and investigate further outlier values.

If outliers are however, introduced due to mechanical error, measurement error or anything else that can't be 
generalised, it is a good idea to remove these outliers before feeding the data to the modeling algorithm. Why? 
Because some algorithms are sensitive to outliers. 


### Which machine learning models are sensitive to outliers?

Some machine learning models are more sensitive to outliers than others. For instance, AdaBoost may treat outliers 
as "hard" cases and put tremendous weights on outliers, therefore producing a model with bad generalisation.

Linear models, in particular Linear Regression, can be also sensitive to outliers.

Decision trees tend to ignore the presence of outliers when creating the branches of their trees. Typically, trees 
make decisions by asking if variable x >= a certain value, and therefore the outlier will fall on each side of the 
branch, but it will be treated equally than the remaining values, regardless of its magnitude.

A recent research article suggests that Neural Networks could also be sensitive to outliers, provided the number of 
outliers is high and the deviation is also high. I would argue that if the number of outliers is high (>15% as 
suggested in the article), then they are no longer outliers, and rather a fair representation of that variable. 
A link to this article can be found in the "Additional reading resources" lecture within this section of the course.


### How can outliers be identified?

Outlier analysis and anomaly detection are a huge field of research devoted to optimise methods and create new 
algorithms to reliably identify outliers. There are a huge number of ways optimised to detect outliers in different 
situations. These are mostly targeted to identify outliers when those are the observations that we indeed want to 
focus on, for example for fraudulent credit card activity.

In this course, however, I will focus on identifying those outliers introduced by mechanical or measurement error. 
Those outliers that are indeed a rare case in the population, and that could be ignored. I will show how to identify 
those outliers, so that in later sections of the course, we can learn how to pre-process them before using the variable 
to train machine learning algorithms.


### Extreme Value Analysis

The most basic form of outlier detection is **Extreme Value Analysis** of 1-dimensional data. The key for this method 
is to determine the statistical tails of the underlying distribution of the variable, and then find the values that sit 
at the very end of the tails.

If the the variable is Normally distributed (Gaussian), then the values that lie outside the mean plus or minus 3 times 
the standard deviation of the variable are considered outliers.

- outliers = mean +/- 3* std


If the variable is skewed distributed, a general approach is to calculate the quantiles, and then the inter-quantile 
range (IQR), as follows:

- IQR = 75th quantile - 25th quantile

An outlier will sit outside the following upper and lower boundaries:

- Upper boundary = 75th quantile + (IQR * 1.5)

- Lower boundary = 25th quantile - (IQR * 1.5)

or for extreme cases:

- Upper boundary = 75th quantile + (IQR * 3)

- Lower boundary = 25th quantile - (IQR * 3)


